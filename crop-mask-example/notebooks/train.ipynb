{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBYSuraxoKJy"
      },
      "source": [
        "# Model training ðŸ‹\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/nasaharvest/openmapflow/blob/main/crop-mask-example/notebooks/train.ipynb)\n",
        "\n",
        "**Description:** Stand alone notebook for training crop-mask models. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdI-wLrbxHZn"
      },
      "source": [
        "# 1. Setup\n",
        "\n",
        "If you don't already have one, obtain a Github Personal Access Token using the steps [here](https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/creating-a-personal-access-token). Save this token somewhere private."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g3otirx9-y6M"
      },
      "outputs": [],
      "source": [
        "email = input(\"Github email: \")\n",
        "username = input(\"Github username: \")\n",
        "\n",
        "!git config --global user.email $username\n",
        "!git config --global user.name $email\n",
        "\n",
        "from getpass import getpass\n",
        "token = getpass('Github Personal Access Token:')\n",
        "\n",
        "# TODO: Generate below two lines from config\n",
        "!git clone https://$username:$token@github.com/nasaharvest/openmapflow.git\n",
        "!cd openmapflow && pip install -r requirements.txt -q\n",
        "%cd openmapflow/crop-mask-example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oWoGz94avN0w"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "from tqdm.notebook import tqdm\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn\n",
        "\n",
        "import torch\n",
        "import wandb\n",
        "import sys\n",
        "sys.path.append(\"..\")\n",
        "\n",
        "from openmapflow.config import RELATIVE_PATHS, FULL_PATHS\n",
        "from openmapflow import PyTorchDataset\n",
        "from openmapflow.config import SUBSET\n",
        "\n",
        "from datasets import datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEusgSrCqxaz"
      },
      "source": [
        "# 2. Download latest data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ls-7sN9Hoew6"
      },
      "outputs": [],
      "source": [
        "for path_key in tqdm([\"models\", \"processed\", \"compressed_features\"]):\n",
        "    !dvc pull {RELATIVE_PATHS[path_key]} -q\n",
        "\n",
        "!tar -xzf {RELATIVE_PATHS[\"compressed_features\"]} -C data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JeANCDe2uJcX"
      },
      "outputs": [],
      "source": [
        "# Currently available models\n",
        "sorted([p.stem for p in FULL_PATHS[\"models\"].glob('*.pt')])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAD4tO5k7nO5"
      },
      "outputs": [],
      "source": [
        "# Available datasets for training and evaluation\n",
        "!cat data/datasets.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gietI36Bykse"
      },
      "source": [
        "# 3. Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c6rJi03Kun9d"
      },
      "outputs": [],
      "source": [
        "model_name = input(\"Model name: \")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = datasets[0].load_labels()"
      ],
      "metadata": {
        "id": "qVsi-fY2_Wnk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class LSTMClassifier(torch.nn.Module):\n",
        "  def __init__(self, input_size=18, hidden_size=128):\n",
        "    super(LSTMClassifier, self).__init__()\n",
        "    self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size, num_layers=1, batch_first=True)\n",
        "    self.linear = nn.Linear(hidden_size, 1)\n",
        "\n",
        "  def forward(self, x):\n",
        "    out, hidden = self.lstm(x)\n",
        "    out = self.linear(out[:, -1]).squeeze(dim=1)\n",
        "    return torch.sigmoid(out)"
      ],
      "metadata": {
        "id": "YNfQueKJ3L8N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lBX3COiquUPN"
      },
      "outputs": [],
      "source": [
        "# ------------ Model -----------------------------------------\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = LSTMClassifier()\n",
        "model = model.to(device)\n",
        "\n",
        "# ------------ Optimizer -------------------------------------\n",
        "lr = 0.001\n",
        "params_to_update = model.parameters()\n",
        "optimizer = torch.optim.SGD(params_to_update, lr=lr, momentum=0.9)\n",
        "criterion = torch.nn.BCELoss()\n",
        "\n",
        "\n",
        "# ------------ Dataloaders -------------------------------------\n",
        "batch_size = 64\n",
        "train_data = PyTorchDataset(df=df[df[SUBSET] == \"training\"], subset=\"training\")\n",
        "test_data = PyTorchDataset(df=df[df[SUBSET] != \"training\"], subset=\"test\")\n",
        "dataloaders = {\n",
        "    \"train\": DataLoader(train_data, batch_size=batch_size, shuffle=True),\n",
        "    \"test\": DataLoader(test_data, batch_size=batch_size, shuffle=False)\n",
        "}\n",
        "batch_amount = {\n",
        "    \"train\": 1 + (len(train_data) // batch_size),\n",
        "    \"test\": 1 + (len(test_data) // batch_size)\n",
        "} "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "Vag_syuI_7LC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#%%wandb\n",
        "num_epochs = 5\n",
        "run = wandb.init(project=\"openmapflow-crop-mask-example\", config={\n",
        "    \"batch_size\": batch_size,\n",
        "    \"num_epochs\": num_epochs,\n",
        "    \"lr\": lr,\n",
        "    \"optimizer\": \"SGD\"\n",
        "})\n",
        "for epoch in range(num_epochs):\n",
        "\n",
        "  for phase in ['train', 'test']:\n",
        "    if phase == 'train':\n",
        "        model.train()  # Set model to training mode\n",
        "    else:\n",
        "        model.eval()   # Set model to evaluate mode\n",
        "\n",
        "    running_loss = 0.0\n",
        "    running_corrects = 0\n",
        "\n",
        "    # Iterate over data.\n",
        "    for x in tqdm(dataloaders[phase], total=batch_amount[phase], desc=phase, leave=False):\n",
        "      inputs, labels = x[0].to(device), x[1].to(device)\n",
        "\n",
        "      # zero the parameter gradients\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # forward\n",
        "      with torch.set_grad_enabled(phase == 'train'):\n",
        "          # Get model outputs and calculate loss\n",
        "          outputs = model(inputs)\n",
        "          loss = criterion(outputs, labels)\n",
        "          preds = outputs > 0.5\n",
        "\n",
        "          # backward + optimize only if in training phase\n",
        "          if phase == 'train':\n",
        "              loss.backward()\n",
        "              optimizer.step()\n",
        "\n",
        "      # statistics\n",
        "      step_loss = loss.item() * inputs.size(0)\n",
        "      if phase == \"train\":\n",
        "        wandb.log({\"train_loss\": step_loss})\n",
        "\n",
        "      running_loss += step_loss\n",
        "      running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "    epoch_loss = running_loss / len(dataloaders[phase].dataset)\n",
        "    epoch_acc = running_corrects.double() / len(dataloaders[phase].dataset)\n",
        "\n",
        "    wandb.log({\n",
        "        f\"{phase}_epoch_loss\": epoch_loss,\n",
        "        f\"{phase}_epoch_acc\": epoch_acc,\n",
        "        \"epoch\": epoch,\n",
        "    })\n",
        "\n",
        "run.finish()"
      ],
      "metadata": {
        "id": "ixEv-__jy8KJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: Save models"
      ],
      "metadata": {
        "id": "YUkdI_yn_h0_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WqRGvmJBwOcv"
      },
      "outputs": [],
      "source": [
        "# Newly available models\n",
        "sorted([p.stem for p in FULL_PATHS[\"models\"].glob('*.pt')])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XG94Q3lAzmyu"
      },
      "source": [
        "# 4. Pushing the model to the repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fbv1fwFNzrnS"
      },
      "outputs": [],
      "source": [
        "!dvc pull {RELATIVE_PATHS[\"models\"]}\n",
        "!dvc push"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9EywOpWv8JDV"
      },
      "outputs": [],
      "source": [
        "# Push changes to github\n",
        "!git checkout -b'$model_name'\n",
        "!git add .\n",
        "!git commit -m 'Trained new: $model_name'\n",
        "!git push --set-upstream origin \"$model_name\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YENWoPX_1AJC"
      },
      "source": [
        "Create a Pull Request so the model can be merged into the main branch. When the branch is merged into main."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "train.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}